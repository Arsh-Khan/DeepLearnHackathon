{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c5_HHutGM75"
      },
      "source": [
        "# Strong Lensing Challenge - Image Super-Resolution\n",
        "\n",
        "Gravitational lensing has been a cornerstone in many cosmology experiments and studies since it was discussed in Einsteinâ€™s calculations back in 1936 and discovered in 1979, and one area of particular interest is the study of dark matter via substructure in strong lensing images. In this challenge, we focus on exploring the potential of ML models in enhancing the resolution of lensing images.\n",
        "\n",
        "This is an example notebook for the Image Super-Resolution Challenge. In this notebook, we demonstrate a simple CNN model implemented using the PyTorch library to solve the task of super-resolution of strong lensing images.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "The Dataset consists of HR and LR pairs. The images have been normalized using min-max normalization, but you are free to use any normalization or data augmentation methods to improve your results.\n",
        "\n",
        "Link to the Dataset: https://drive.google.com/file/d/1lUOGo2B0Rhxwj_TGZSVEdZJ79GdI7awa/view?usp=sharing\n",
        "\n",
        "### Evaluation Metrics\n",
        "\n",
        "* MSE, SSIM and PSNR   \n",
        "\n",
        "The model performance will be tested on the hidden test dataset based on the above metrics.\n",
        "\n",
        "### Instructions for using the notebook\n",
        "\n",
        "1. Use GPU acceleration: (Edit --> Notebook settings --> Hardware accelerator --> GPU)\n",
        "2. Run the cells: (Runtime --> Run all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIiqNE2UGLev"
      },
      "outputs": [],
      "source": [
        "# Check if the dataset folder is missing\n",
        "import os\n",
        "if not os.path.exists('./dataset'):\n",
        "    # Download and extract the dataset\n",
        "    !gdown http://drive.google.com/uc?id=1lUOGo2B0Rhxwj_TGZSVEdZJ79GdI7awa\n",
        "    !unzip -q dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPMhi3uvHTBK"
      },
      "source": [
        "## Multi-Class Classification using a Supervised Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "513RtRF4Hf3Z"
      },
      "source": [
        "### 1. Data Visualization and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR-nMgqoIary"
      },
      "source": [
        "#### 1.1 Import all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "agXdpFwPPiHw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.utils.data as data\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "import torch.nn.functional as F\n",
        "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mw4NndbHsiY"
      },
      "source": [
        "#### 1.2 Preview the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0m86HY9DJSl"
      },
      "outputs": [],
      "source": [
        "# Define the input paths\n",
        "train_hr_path = './dataset/train/HR'\n",
        "train_hr_files = [os.path.join(train_hr_path, f) for f in os.listdir(train_hr_path) if f.endswith(\".npy\")]\n",
        "train_lr_path = './dataset/train/LR'\n",
        "train_lr_files = [os.path.join(train_lr_path, f) for f in os.listdir(train_lr_path) if f.endswith(\".npy\")]\n",
        "\n",
        "# Number of samples to display\n",
        "n = 5\n",
        "\n",
        "# Plot the samples\n",
        "i = 1\n",
        "print('High-Resolution (HR) samples: ')\n",
        "plt.rcParams['figure.figsize'] = [14, 14]\n",
        "for image in train_hr_files[:n]:\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(np.load(image).reshape(128,128), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    i += 1\n",
        "plt.show()\n",
        "\n",
        "print('Low-Resolution (LR) samples: ')\n",
        "plt.rcParams['figure.figsize'] = [14, 14]\n",
        "for image in train_lr_files[:n]:\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(np.load(image).reshape(64,64), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYWK0ZkMIMSr"
      },
      "source": [
        "#### 1.3 Import Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yrkV-fO9mWI"
      },
      "outputs": [],
      "source": [
        "# Set Batch Size\n",
        "batch_size = 100\n",
        "\n",
        "# Define Data Loaders\n",
        "class SuperResolutionDataset(data.Dataset):\n",
        "    def __init__(self, lr_path, hr_path):\n",
        "        self.lr_files = [os.path.join(lr_path, f) for f in os.listdir(lr_path) if f.endswith(\".npy\")]\n",
        "        self.hr_files = [os.path.join(hr_path, f) for f in os.listdir(hr_path) if f.endswith(\".npy\")]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.lr_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        lr_image = np.load(self.lr_files[idx])\n",
        "        hr_image = np.load(self.hr_files[idx])\n",
        "        return torch.from_numpy(lr_image).float(), torch.from_numpy(hr_image).float()\n",
        "\n",
        "train_data = SuperResolutionDataset('./dataset/train/LR', './dataset/train/HR')\n",
        "train_data_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_data = SuperResolutionDataset('./dataset/val/LR', './dataset/val/HR')\n",
        "val_data_loader = data.DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABBx_F7oI_vC"
      },
      "source": [
        "### 2. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clDeWqesKU_8"
      },
      "source": [
        "#### 2.1 Defining a Super-Resolution CNN Model\n",
        "\n",
        "You may refer to this [article](https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148) to learn about Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlDjFP-mraJG"
      },
      "outputs": [],
      "source": [
        "class SRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SRCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=9, padding=4)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        x = F.interpolate(x, size=(128, 128), mode='bicubic', align_corners=False)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SRCNN().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ixy2T3PKpes"
      },
      "source": [
        "#### 2.2 Training the Super-Resolution CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dsVNm2J7K67"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "criteria = nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# Train the model\n",
        "n_epochs = 20 # Number of Training Epochs\n",
        "loss_array = []\n",
        "pbar = tqdm(range(1, n_epochs+1))\n",
        "for epoch in pbar:\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for step, (lr, hr) in enumerate(train_data_loader):\n",
        "\n",
        "        lr = Variable(lr).type(torch.FloatTensor).to(device)\n",
        "        hr = Variable(hr).type(torch.FloatTensor).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(lr)\n",
        "        loss = criteria(outputs, hr)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss = train_loss / len(train_data_loader)\n",
        "    # Display the Training Stats\n",
        "    pbar.set_postfix({ 'Training Loss': train_loss })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s73f62tkLopN"
      },
      "source": [
        "### 3. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPIMrzmAMpsv"
      },
      "source": [
        "#### 3.1 Testing the Super-Resolution CNN Model on Validation Data - Calculate Quantitative Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Metrics\n",
        "\n",
        "# Get predications\n",
        "model.eval()\n",
        "out = []\n",
        "with torch.no_grad():\n",
        "    for lr, hr in val_data_loader:\n",
        "        lr = lr.to(device)\n",
        "        hr = hr.to(device)\n",
        "        recon = model(lr)\n",
        "        out.append(recon.cpu().detach().numpy())\n",
        "        del lr, hr, recon\n",
        "        torch.cuda.empty_cache()\n",
        "dataSR = np.concatenate(out, axis=0)\n",
        "\n",
        "# Prepare ground truth for comparison\n",
        "val_hr = []\n",
        "for _, hr in val_data_loader:\n",
        "    val_hr.append(hr.cpu().numpy())\n",
        "val_hr = np.concatenate(val_hr, axis=0)\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"Metrics:\")\n",
        "criteria = nn.MSELoss()\n",
        "criteria2 = nn.L1Loss()\n",
        "losses = []\n",
        "losses2 = []\n",
        "Ssim = []\n",
        "Psnr = []\n",
        "\n",
        "for i in range(dataSR.shape[0]):\n",
        "    losses.append(criteria(torch.from_numpy(dataSR[i]), torch.from_numpy(val_hr[i])))\n",
        "    losses2.append(criteria2(torch.from_numpy(dataSR[i]), torch.from_numpy(val_hr[i])))\n",
        "    Ssim.append(ssim(val_hr[i][0], dataSR[i][0], data_range=dataSR[i][0].max() - dataSR[i][0].min()))\n",
        "    Psnr.append(psnr(val_hr[i][0], dataSR[i][0], data_range=dataSR[i][0].max() - dataSR[i][0].min()))\n",
        "\n",
        "print(\"Average MSE super resolution samples: \" + str('%.7f'%np.average(losses)))\n",
        "print(\"Average L1 super resolution samples: \" + str('%.7f'%np.average(losses2)))\n",
        "print(\"Average SSIM super resolution samples: \" + str('%.5f'%np.average(Ssim)))\n",
        "print(\"Average PSNR super resolution samples: \" + str('%.5f'%np.average(Psnr)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2 Visualize Outputs for Qualitative Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emtSHxk6xsOG"
      },
      "outputs": [],
      "source": [
        "# Visualize Outputs\n",
        "with torch.no_grad():\n",
        "    for lr, hr in val_data_loader:\n",
        "        lr = lr.to(device)\n",
        "        hr = hr.to(device)\n",
        "        output = model(lr)\n",
        "\n",
        "        lr = lr.cpu().numpy()\n",
        "        output = output.cpu().numpy()\n",
        "        hr = hr.cpu().numpy()\n",
        "\n",
        "        # Display the results\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        for i in range(5):\n",
        "            plt.subplot(3, 5, i + 1)\n",
        "            plt.imshow(lr[i].reshape(64, 64), cmap='gray')\n",
        "            plt.title('Low Res')\n",
        "            plt.axis('off')\n",
        "            plt.subplot(3, 5, i + 6)\n",
        "            plt.imshow(hr[i].reshape(128, 128), cmap='gray')\n",
        "            plt.title('High Res')\n",
        "            plt.axis('off')\n",
        "            plt.subplot(3, 5, i + 11)\n",
        "            plt.imshow(output[i].reshape(128, 128), cmap='gray')\n",
        "            plt.title('Output')\n",
        "            plt.axis('off')\n",
        "        plt.show()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHD8VEzyOuad"
      },
      "source": [
        "## Submission Guidelines\n",
        "\n",
        "* You are required to submit a Google Colab Jupyter Notebook clearly showing your implementation along with the evaluation metrics (ROC curve, and AUC score) for the validation data.\n",
        "* You must also submit the final trained model, including the model architecture and the trained weights ( For example: HDF5 file, .pb file, .pt file, etc. )\n",
        "* You can use this example notebook as a template for your work.\n",
        "\n",
        "> **_NOTE:_**  You are free to use any ML framework such as PyTorch, Keras, TensorFlow, etc."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Hackathon_Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
